from fastapi import FastAPI, HTTPException
import sys
import nltk

from NewDatasetModel.testGo import predict_with_full_rules 
from JigsawModel.TestJigsaw import load_prediction_assets, predict_and_explain

sys.stdout.reconfigure(encoding='utf-8')
app = FastAPI()

jigsaw_model = None
jigsaw_tokenizer = None
jigsaw_thresholds = None


def initialize_nltk():
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• NLTK ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô"""
    required_packages = ['punkt', 'wordnet', 'omw-1.4', 'stopwords']
    print("üöÄ Initializing NLTK dependencies...")
    for package in required_packages:
        try:
            if package == 'punkt': nltk.data.find(f'tokenizers/{package}')
            elif package == 'stopwords': nltk.data.find(f'corpora/{package}')
            else: nltk.data.find(f'corpora/{package}.zip')
            print(f"‚úÖ NLTK package '{package}' found.")
        except LookupError:
            print(f"üö® NLTK package '{package}' not found. Downloading...")
            nltk.download(package, quiet=True)
    print("‚úÖ NLTK is ready.")

@app.on_event("startup")
def startup_event():
    """‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà FastAPI ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô"""
    global jigsaw_model, jigsaw_tokenizer, jigsaw_thresholds
    
    initialize_nltk()
    
    print("üöÄ Loading Jigsaw toxicity model...")
    try:
        jigsaw_model, jigsaw_tokenizer, jigsaw_thresholds = load_prediction_assets()
        if all((jigsaw_model, jigsaw_tokenizer, jigsaw_thresholds is not None)):
             print(" Jigsaw model loaded successfully!")
        else:
             print(" Error loading Jigsaw model!")
    except Exception as e:
        print(f" A critical error occurred while loading the Jigsaw model: {e}")


@app.get("/analyze")
def analyze_comment(comment: str): 
    text_batch = [comment]
    
    sentiment_result = predict_with_full_rules(comment)
    print("--------------------------------------------------------------------------------")
    print(f"Sentiment Result: {sentiment_result}")
    print("--------------------------------------------------------------------------------")

    # ‚ú® 1. ‡πÄ‡∏û‡∏¥‡πà‡∏° key 'explanation' ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
    toxicity_analysis = {
        "is_toxic": False, 
        "toxic_types": [],
        "explanation": []  # ‡πÄ‡∏û‡∏¥‡πà‡∏° key ‡∏ô‡∏µ‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ
    }
    
    if sentiment_result == "negative":
        if not all((jigsaw_model, jigsaw_tokenizer, jigsaw_thresholds)):
            raise HTTPException(
                status_code=503, 
                detail="Toxicity model is not available or failed to load."
            )
        
        # ‚ú® 2. ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏õ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà predict_and_explain
        # ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏ô TestJigsaw.py ‡∏ä‡∏∑‡πà‡∏≠ predict_and_explain
        toxicity_results = predict_and_explain(text_batch, jigsaw_model, jigsaw_tokenizer, jigsaw_thresholds)
        
        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏£‡∏Å (index 0)
        result_data = toxicity_results[0]
        prediction_dict = result_data['prediction']
        triggered_labels = [label for label, value in prediction_dict.items() if value == 1]
        
        if triggered_labels:
            toxicity_analysis["is_toxic"] = True
            toxicity_analysis["toxic_types"] = triggered_labels
            
            top_explanation = result_data['explanation'][:3] 
            
            # ‚ú® ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ: ‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞ word (‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å‡∏Ç‡∏≠‡∏á tuple) ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤
            just_the_words = [word for word, score in top_explanation]
            
            toxicity_analysis["explanation"] = just_the_words

    # ‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏ß‡πà‡∏≤ toxicity_analysis ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• explanation ‡∏≠‡∏¢‡∏π‡πà‡∏î‡πâ‡∏ß‡∏¢
    return { 
        "comment": comment, 
        "sentiment_group": sentiment_result,
        "toxicity_analysis": toxicity_analysis
    }

