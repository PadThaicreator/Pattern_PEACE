from fastapi import FastAPI, HTTPException
import sys
import nltk

# --- ‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£ Import ---
# ‚ö†Ô∏è ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ ‡∏à‡∏≤‡∏Å test ‡πÄ‡∏õ‡πá‡∏ô testGo
from NewDatasetModel.testGo import predict_with_full_rules 
# ‚ö†Ô∏è ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ ‡∏à‡∏≤‡∏Å Test ‡πÄ‡∏õ‡πá‡∏ô TestJigsaw
from JigsawModel.TestJigsaw import load_prediction_assets, predict_toxicity

sys.stdout.reconfigure(encoding='utf-8')
app = FastAPI()

# --- ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ Global ---
jigsaw_model = None
jigsaw_tokenizer = None
jigsaw_thresholds = None

# --- ‡πÅ‡∏ö‡πà‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏° Sentiment/Emotion ---
positive_emotions = ["admiration", "amusement", "approval", "caring", "desire", "excitement", "gratitude", "joy", "love", "optimism", "pride", "relief"]
negative_emotions = ["anger", "annoyance", "disappointment", "disapproval", "disgust", "embarrassment", "fear", "grief", "nervousness", "remorse", "sadness"]
ambiguous_emotions = ["confusion", "curiosity", "realization", "surprise"]
neutral_emotions = ["neutral"]

def initialize_nltk():
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• NLTK ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô"""
    required_packages = ['punkt', 'wordnet', 'omw-1.4', 'stopwords']
    print("üöÄ Initializing NLTK dependencies...")
    for package in required_packages:
        try:
            if package == 'punkt': nltk.data.find(f'tokenizers/{package}')
            elif package == 'stopwords': nltk.data.find(f'corpora/{package}')
            else: nltk.data.find(f'corpora/{package}.zip')
            print(f"‚úÖ NLTK package '{package}' found.")
        except LookupError:
            print(f"üö® NLTK package '{package}' not found. Downloading...")
            nltk.download(package, quiet=True)
    print("‚úÖ NLTK is ready.")

@app.on_event("startup")
def startup_event():
    """‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà FastAPI ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô"""
    global jigsaw_model, jigsaw_tokenizer, jigsaw_thresholds
    
    initialize_nltk()
    
    print("üöÄ Loading Jigsaw toxicity model...")
    try:
        jigsaw_model, jigsaw_tokenizer, jigsaw_thresholds = load_prediction_assets()
        if all((jigsaw_model, jigsaw_tokenizer, jigsaw_thresholds is not None)):
             print("‚úÖ Jigsaw model loaded successfully!")
        else:
             print("üî• Error loading Jigsaw model!")
    except Exception as e:
        print(f"üî• A critical error occurred while loading the Jigsaw model: {e}")


@app.get("/analyze")
def analyze_comment(comment: str): 
    text_batch = [comment]
    
    sentiment_result = predict_with_full_rules(comment)
    print("--------------------------------------------------------------------------------")
    print(sentiment_result)
    print("--------------------------------------------------------------------------------")

    toxicity_analysis = {"is_toxic": False, "toxic_types": []}

    # üí° ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Logic: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ sentiment ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏° negative ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    if sentiment_result == "negative":
        if not all((jigsaw_model, jigsaw_tokenizer, jigsaw_thresholds is not None)):
            raise HTTPException(
                status_code=503, 
                detail="Toxicity model is not available or failed to load."
            )
        
        toxicity_results = predict_toxicity(text_batch, jigsaw_model, jigsaw_tokenizer, jigsaw_thresholds)
        prediction_dict = toxicity_results[0]['prediction']
        triggered_labels = [label for label, value in prediction_dict.items() if value == 1]
        
        if triggered_labels:
            toxicity_analysis["is_toxic"] = True
            toxicity_analysis["toxic_types"] = triggered_labels

    # üí° ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Response: ‡πÉ‡∏´‡πâ‡∏°‡∏µ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á JSON ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏™‡∏°‡∏≠
    return { 
        "comment": comment, 
        "sentiment_group": sentiment_result,
        "toxicity_analysis": toxicity_analysis
    }

